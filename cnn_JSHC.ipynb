{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "from keras.layers import Dropout\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Make y_train and y_test categoricals\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a bigger corpus\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make a model\n",
    "\n",
    "\"\"\"\n",
    "def create_model(conv_layers=1,neurons=128):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Convolution2D(32, 3, 3, input_shape = x_train.shape[1:], activation = 'relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    for i in range(0,conv_layers):\n",
    "        classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "        classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    classifier.add(Dropout(0.5))\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense(output_dim = neurons, activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim = 10, activation = 'softmax'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\"\"\"\n",
    "\n",
    "def create_model(neurons=128,lstm_layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "    model.add(Convolution2D(32, (3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    for i in range(0,lstm_layers):\n",
    "        model.add(Convolution2D(64, (3, 3), padding='same'))\n",
    "        model.add(Convolution2D(64, (3, 3)))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(output_dim = neurons, activation = 'relu'))\n",
    "    model.add(Dense(output_dim = 10, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebashc/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "/home/sebashc/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 82s 52ms/step - loss: 1.6717 - accuracy: 0.3972\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 81s 52ms/step - loss: 1.4205 - accuracy: 0.4943\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 81s 52ms/step - loss: 1.3341 - accuracy: 0.5272\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 81s 52ms/step - loss: 1.2882 - accuracy: 0.5443\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 82s 52ms/step - loss: 1.2556 - accuracy: 0.5566\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 82s 53ms/step - loss: 1.2310 - accuracy: 0.5649\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 82s 53ms/step - loss: 1.2176 - accuracy: 0.5739\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 83s 53ms/step - loss: 1.2002 - accuracy: 0.5769\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 82s 52ms/step - loss: 1.1907 - accuracy: 0.5818\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 83s 53ms/step - loss: 1.1786 - accuracy: 0.5866\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 84s 53ms/step - loss: 1.1699 - accuracy: 0.5912\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 84s 54ms/step - loss: 1.1709 - accuracy: 0.5928\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 83s 53ms/step - loss: 1.1575 - accuracy: 0.5923\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 84s 54ms/step - loss: 1.1562 - accuracy: 0.5961\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 85s 54ms/step - loss: 1.1485 - accuracy: 0.5979\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 85s 54ms/step - loss: 1.1489 - accuracy: 0.5991\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 84s 54ms/step - loss: 1.1406 - accuracy: 0.6030\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 85s 55ms/step - loss: 1.1392 - accuracy: 0.60370s - loss: 1.1390 - accu\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 86s 55ms/step - loss: 1.1198 - accuracy: 0.6087\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 86s 55ms/step - loss: 1.1334 - accuracy: 0.6065\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 87s 55ms/step - loss: 1.1230 - accuracy: 0.6104\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 87s 56ms/step - loss: 1.1223 - accuracy: 0.6108\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 88s 56ms/step - loss: 1.1196 - accuracy: 0.6077\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 88s 56ms/step - loss: 1.1148 - accuracy: 0.6103\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 88s 56ms/step - loss: 1.1176 - accuracy: 0.6092\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 88s 56ms/step - loss: 1.1165 - accuracy: 0.6122\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 88s 56ms/step - loss: 1.1157 - accuracy: 0.6124\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 88s 56ms/step - loss: 1.1063 - accuracy: 0.6168\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 88s 56ms/step - loss: 1.1092 - accuracy: 0.6144\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 89s 57ms/step - loss: 1.1122 - accuracy: 0.6131\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 89s 57ms/step - loss: 1.1049 - accuracy: 0.6180\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 89s 57ms/step - loss: 1.1017 - accuracy: 0.6186\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 88s 57ms/step - loss: 1.1164 - accuracy: 0.6151\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 89s 57ms/step - loss: 1.1028 - accuracy: 0.6143\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 1.1049 - accuracy: 0.6158\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 1.1013 - accuracy: 0.6184\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 89s 57ms/step - loss: 1.0964 - accuracy: 0.6218\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 90s 58ms/step - loss: 1.0956 - accuracy: 0.6204\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 90s 58ms/step - loss: 1.0966 - accuracy: 0.6206\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 91s 58ms/step - loss: 1.0961 - accuracy: 0.6206\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 90s 58ms/step - loss: 1.0963 - accuracy: 0.6187\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 91s 58ms/step - loss: 1.0921 - accuracy: 0.6224\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 92s 59ms/step - loss: 1.0989 - accuracy: 0.6189\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 91s 59ms/step - loss: 1.0917 - accuracy: 0.6251\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 90s 58ms/step - loss: 1.0917 - accuracy: 0.6236\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 91s 58ms/step - loss: 1.0883 - accuracy: 0.6258\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 91s 58ms/step - loss: 1.0886 - accuracy: 0.6255\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 91s 58ms/step - loss: 1.0901 - accuracy: 0.6215\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 91s 58ms/step - loss: 1.0880 - accuracy: 0.6260\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 91s 58ms/step - loss: 1.0819 - accuracy: 0.6256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6c5b3739b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "classifier=create_model(conv_layers=2,neurons=128)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "classifier.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(x_train) / 32, epochs=100)\n",
    "\"\"\"\n",
    "\n",
    "classifier=create_model()\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "classifier.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(x_train) / 32, epochs=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[524  84  25   2   3   1  23  57  50 231]\n",
      " [  3 729   0   1   0   0  15   2  20 230]\n",
      " [ 65  69 180   8  17  27 260 184  18 172]\n",
      " [ 33  92   8 102   7  63 283 120  25 267]\n",
      " [ 20  17  14   6 155  11 390 237   9 141]\n",
      " [ 10  55   5  34   8 236 199 172   9 272]\n",
      " [  7   9   2   5   3   3 881  15   3  72]\n",
      " [  8  15   4   2   7  13  60 760   4 127]\n",
      " [ 58  78   1   0   0   0   6   8 477 372]\n",
      " [  5  33   0   0   0   0   5   4   3 950]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.71      0.60       733\n",
      "           1       0.73      0.62      0.67      1181\n",
      "           2       0.18      0.75      0.29       239\n",
      "           3       0.10      0.64      0.18       160\n",
      "           4       0.15      0.78      0.26       200\n",
      "           5       0.24      0.67      0.35       354\n",
      "           6       0.88      0.42      0.56      2122\n",
      "           7       0.76      0.49      0.59      1559\n",
      "           8       0.48      0.77      0.59       618\n",
      "           9       0.95      0.34      0.50      2834\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.50      0.62      0.46     10000\n",
      "weighted avg       0.75      0.50      0.54     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# summary of the performance\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "Y_pred = classifier.predict(x_test)\n",
    "Y_pred = np.argmax(Y_pred, axis = 1)\n",
    "\n",
    "CM = confusion_matrix(np.argmax(y_test, axis = 1), Y_pred)\n",
    "print(\"\\n\"+\"Confusion Matrix:\" + \"\\n\")\n",
    "print(CM)\n",
    "\n",
    "print(\"\\n\"+\"Classification Report\"+\"\\n\")\n",
    "print(classification_report(Y_pred,np.argmax(y_test, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
